{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIooTcH//6db7CawU3ytYT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandruBrezuleanu/Advanced-Topics-in-Neural-Networks-Template-2023/blob/main/Tema3_RN_Brezuleanu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mog89e7LWzqx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "import sys\n",
        "import torch.nn.functional as TF\n",
        "\n",
        "#m=20\n",
        "\n",
        "#X = torch.rand((m,784))\n",
        "W1 = torch.rand((784,100))/10\n",
        "W2 = torch.rand((100,10))/10\n",
        "#y = torch.zeros((m,10))\n",
        "\n",
        "b1 = torch.rand((100))/10\n",
        "b2 = torch.rand((10))/10\n",
        "\n",
        "lr = 0.01\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_function(x):\n",
        "  return 1/(1+torch.exp(-x))\n",
        "\n",
        "def forward(X:Tensor, W1:Tensor, W2:Tensor, b1:Tensor, b2:Tensor):\n",
        "  z1 = X @ W1 + b1\n",
        "  y_hat1 = sigmoid_function(z1)\n",
        "\n",
        "  z2 = y_hat1 @ W2 + b2\n",
        "  y_hat2 = sigmoid_function(z2)\n",
        "  return y_hat2\n",
        "\n",
        "def train_batch(X:Tensor, W1:Tensor, W2:Tensor, b1:Tensor, b2:Tensor, y_true: Tensor, lr:float):\n",
        "  z1 = X @ W1 + b1\n",
        "  y_hat1 = sigmoid_function(z1)\n",
        "  z2 = y_hat1 @ W2 + b2\n",
        "  y_hat2 = sigmoid_function(z2)\n",
        "  error2 = y_hat2 - y_true\n",
        "  error1 = y_hat1 * (1 - y_hat1) * (error2 @ W2.T)\n",
        "\n",
        "  for index, line in enumerate(y_hat1):\n",
        "    new_x = line.unsqueeze(0)\n",
        "    new_y = error2[index].unsqueeze(0)\n",
        "    diff_W2 = new_x.T * new_y\n",
        "    W2 = W2 - lr * diff_W2\n",
        "  for index, line in enumerate(X):\n",
        "    new_x = line.unsqueeze(0)\n",
        "    new_y = error1[index].unsqueeze(0)\n",
        "    diff_W1 = new_x.T * new_y\n",
        "    W1 = W1 - lr * diff_W1\n",
        "\n",
        "  b2 = b2 - lr * error2.mean(axis=0)\n",
        "  b1 = b1 - lr * error1.mean(axis=0)\n",
        "  return W1,W2,b1,b2\n",
        "\n",
        "def train_epoch(X:Tensor, W1:Tensor, W2:Tensor, b1:Tensor, b2:Tensor, y_true: Tensor, lr:float, batch_size):\n",
        "  for i in range(0, X.shape[0], batch_size):\n",
        "      x = X[i: i + batch_size]\n",
        "      y = y_true[i: i + batch_size]\n",
        "      W1,W2,b1,b2 = train_batch(x,W1,W2,b1,b2,y,lr)\n",
        "\n",
        "  return W1,W2,b1,b2\n",
        "\n",
        "def train_mlp(X:Tensor, W1:Tensor, W2:Tensor, b1:Tensor, b2:Tensor, y_true: Tensor, lr:float):\n",
        "    epoch_size = 30\n",
        "    batch_size = 100\n",
        "    for epoch in range(epoch_size):\n",
        "      W1,W2,b1,b2 = train_epoch(X,W1,W2,b1,b2,y_true,lr,batch_size)\n",
        "    return W1,W2,b1,b2"
      ],
      "metadata": {
        "id": "55k9S7JmW4L8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('mnist_train.csv')\n",
        "label = train_data['label']\n",
        "label_train_tensor = torch.LongTensor(label)\n",
        "train_tensor = torch.tensor(train_data.drop( 'label', axis = 1).values, dtype=torch.float)\n",
        "train_tensor = train_tensor / (255 * 10)\n",
        "\n",
        "y_train = torch.zeros((len(label), 10))\n",
        "for index, val in enumerate(label):\n",
        "  y_train[index][val] = 1\n"
      ],
      "metadata": {
        "id": "tdskSPNjnK7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('mnist_test.csv')\n",
        "label_test = test_data['label']\n",
        "label_test_tensor = torch.LongTensor(label_test)\n",
        "test_tensor = torch.tensor(test_data.drop( 'label', axis = 1).values, dtype=torch.float)\n",
        "test_tensor = test_tensor / (255 *10)\n",
        "\n",
        "y_test = torch.zeros((len(label_test), 10))\n",
        "for index, val in enumerate(label_test):\n",
        "  y_test[index][val] = 1"
      ],
      "metadata": {
        "id": "-BB5-76MfHDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "W1,W2,b1,b2 = train_mlp(train_tensor, W1,W2,b1,b2,y_train,lr)"
      ],
      "metadata": {
        "id": "6wmwGWpngF5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50cc2bec-1de7-4f11-f856-691ea18c97b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 39s, sys: 419 ms, total: 4min 40s\n",
            "Wall time: 4min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = forward(train_tensor, W1,W2,b1,b2)\n",
        "\n",
        "correct=0\n",
        "for index, row in enumerate(y_train):\n",
        "  if torch.argmax(row) == torch.argmax(predicted_y[index]):\n",
        "    correct+=1\n",
        "\n",
        "print(\"Accuracy on training set: \" + str((100 * correct)/len(train_tensor)))\n",
        "\n",
        "loss = TF.cross_entropy(predicted_y, label_train_tensor)\n",
        "\n",
        "# Print the computed loss\n",
        "print(f\"Cross entropy loss on training set: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsC9AsRaRI46",
        "outputId": "52bd01d7-0f54-438b-e3b8-e6082ed86cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on training set: 95.15\n",
            "Cross entropy loss on training set: 1.5578364133834839\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_y = forward(test_tensor, W1,W2,b1,b2)\n",
        "\n",
        "correct=0\n",
        "for index, row in enumerate(y_test):\n",
        "  if torch.argmax(row) == torch.argmax(predicted_y[index]):\n",
        "    correct+=1\n",
        "\n",
        "print(\"Accuracy on validation set: \" + str((100 * correct)/len(test_tensor)))\n",
        "\n",
        "loss = TF.cross_entropy(predicted_y, label_test_tensor)\n",
        "\n",
        "# Print the computed loss\n",
        "print(f\"Cross entropy loss on validation test: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgrJOx5KbTuR",
        "outputId": "d2d73093-3669-4208-fea3-9f3d797242dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set: 94.93\n",
            "Cross entropy loss on validation test: 1.557747721672058\n"
          ]
        }
      ]
    }
  ]
}